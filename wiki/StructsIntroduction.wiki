#FST struct emulation

= Introduction =

_In C++, one needs to sacrifice performance in order to get convenience, in Java one needs to sacrifice convenience in order to get performance_


While serialization can flatten any Object Graph into a byte array, one needs to deserialize the Object in order to access the data contained. Frequently (offheap objects, locality) one would like to access the data without the costly "deserialization"-part.

FSTStructs provide a way to store and access data in a deterministic structured layout in a continuous chunk of memory.
I therefore use runtime byte code generation and (may change in future) the Unsafe class in order to redirect direct member access of method bodies to an underlying {{{byte[]}}}} array.

While there are a lot compromises to be made (an orthogonal implementation would require VM extensions) when defining FSTStructs, there are a lot of benefits "flattening" data structures keeping them accessible:

  * very low GC cost (store GB of structured data with <10ms Full GC duration) 
  * (un-)marshalling is equal to a memory copy. This speeds up inter process communication using shared memory or network messages.
  * use memory mapped files to virtually enlarge your memory, as it is possibble to control memory layout of your data
  * faster iteration of complex data structures compared to On-Heap due to control over in memory layout and "pointer-alike" memory access patterns
  * data structures can be de/encoded easy from external languages


https://fast-serialization.googlecode.com/files/structlayout.PNG

==How does this work ?==

Structs are stored in byte arrays, additionally FST generates "pointer"-alike Wrapper Classes providing access to the the flattened object inside the byte array. One could put arbitrary amounts of structs into a single byte array.


Code Examples:
{{{
        // build template
        TestInstrument ti = new TestInstrument();
        // max 4 legs
        ti.legs = new TestInstrumentLeg[] { new TestInstrumentLeg(), null, null, null };
        StructArray<TestInstrument> instruments = fac.toStructArray(100000, ti);

}}} 

results in a flat array of in-place copies of the given "template" instacne. One can access this like a normal object structures like

{{{
        sum = 0;
        for ( int i = 0; i < instruments.size(); i++ ) {
            sum+=instruments.get(i).getAccumulatedQty();
        }
}}}

One can create a pointer (structure wrapper) to pick an arbitrary element and pass it like a regular object to other code like:

{{{
        TestInstrumentLeg toDetach = instruments.get(i).legs(1);
        toDetach.detach();
}}}

One can achieve unmatched iteration performance (err.. requires some C-alike coding)
{{{
        sum = 0;
        TestInstrument p = instruments.createPointer(0);
        TestInstrumentLeg legp = p.legs(0).detach();
        final int legSiz = legp.getByteSize();
        // relative offset of first TestInstrumentLeg of StructArray<TestInstrumentLeg>
        final long legoff = legp.___offset - p.___offset; 
        for (int i=0; i < count; i++ ) {
            int legs = p.getNumLegs();
            sum++;
            for ( int k = 0; k < legs; k++ ) {
                sum+=legp.getLegQty();
                legp.next(legSiz);
            }
            p.next(siz);
            legp.___offset=p.___offset+legoff;
        }
}}}

While this is real ugly code, it runs about twice as fast as any possible on-heap implementation (with similar data structure) due to improved locality and the lack of dereferencing. Since everything is fixed size, one can create a kind of pointer to a substructure element and iterate over the whole structure array by simply moving the base pointer.

Emebedded Objects can be rewritten, however one gets an exception if the new object requires more bytes than the previous. 